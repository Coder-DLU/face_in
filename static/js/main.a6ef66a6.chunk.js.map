{"version":3,"sources":["assest/hey_sondn.mp3","App.js","reportWebVitals.js","index.js"],"names":["sound","Howl","src","soundURL","TOUCHED_LABLE","App","video","useRef","classifier","canPlaySound","mobilenetModule","useState","touched","setTouched","init","a","console","log","setupCamera","current","knnClassifier","mobilenet","initNotifications","cooldown","Promise","resolve","reject","navigator","getUserMedia","webkitGetUserMedia","mozGetUserMedia","msGetUserMedia","stream","srcObject","addEventListener","error","train","label","i","parseInt","training","embedding","infer","addExample","sleep","run","predictClass","result","confidences","play","notify","body","ms","setTimeout","useEffect","on","className","ref","autoPlay","onClick","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"wWAAe,G,OAAA,IAA0B,uC,iBCSrCA,EAAQ,IAAIC,OAAK,CACjBC,IAAK,CAACC,KAKJC,EAAgB,UA6JPC,MAxJf,WACI,IAAMC,EAAQC,mBACRC,EAAaD,mBACbE,EAAeF,kBAAO,GACtBG,EAAkBH,mBACxB,EAA8BI,oBAAS,GAAvC,mBAAOC,EAAP,KAAgBC,EAAhB,KAEMC,EAAI,uCAAG,sBAAAC,EAAA,6DACTC,QAAQC,IAAI,WADH,SAEHC,IAFG,cAGTF,QAAQC,IAAI,WAEZT,EAAWW,QAAUC,MALZ,SAMuBC,MANvB,OAMTX,EAAgBS,QANP,OAOTH,QAAQC,IAAI,iBACZD,QAAQC,IAAI,sCAEZK,YAAkB,CAAEC,SAAU,MAVrB,4CAAH,qDAaJL,EAAc,WAChB,OAAO,IAAIM,SAAQ,SAACC,EAASC,GACzBC,UAAUC,aAAeD,UAAUC,cAC/BD,UAAUE,oBACVF,UAAUG,iBACVH,UAAUI,eACVJ,UAAUC,aACVD,UAAUC,aAAa,CAAEtB,OAAO,IAC5B,SAAA0B,GACI1B,EAAMa,QAAQc,UAAYD,EAC1B1B,EAAMa,QAAQe,iBAAiB,aAAcT,MAEjD,SAAAU,GAAK,OAAIT,EAAOS,MAGpBT,QAINU,EAAK,uCAAG,WAAMC,GAAN,eAAAtB,EAAA,sDACNC,QAAQC,IAAR,UAAeoB,EAAf,gCACSC,EAAI,EAFP,YAEUA,EA7CL,IA2CL,uBAGFtB,QAAQC,IAAR,mBAAwBsB,UAAUD,EAAE,GA9C7B,GA8CmD,KAA1D,MAHE,SAKIE,EAASH,GALb,SAEgCC,EAFhC,0DAAH,sDAiBLE,EAAW,SAAAH,GACb,OAAO,IAAIb,QAAJ,uCAAY,WAAMC,GAAN,eAAAV,EAAA,6DACT0B,EAAY/B,EAAgBS,QAAQuB,MACtCpC,EAAMa,SACN,GAEJX,EAAWW,QAAQwB,WAAWF,EAAWJ,GAL1B,SAMTO,EAAM,KANG,OAOfnB,IAPe,2CAAZ,wDAWLoB,EAAG,uCAAG,8BAAA9B,EAAA,6DACF0B,EAAY/B,EAAgBS,QAAQuB,MACtCpC,EAAMa,SACN,GAHI,SAKaX,EAAWW,QAAQ2B,aAAaL,GAL7C,cAKFM,EALE,OAOR/B,QAAQC,IAAI,SAAU8B,EAAOV,OAC7BrB,QAAQC,IAAI,eAAgB8B,EAAOC,aAG/BD,EAAOV,QAAUjC,GACjB2C,EAAOC,YAAYD,EAAOV,OAlFX,IAoFX5B,EAAaU,UACbV,EAAaU,SAAU,EACvBnB,EAAMiD,QAEVjC,QAAQC,IAAI,WACZjB,EAAMiD,OACNC,YAAO,kBAAc,CAAEC,KAAM,kBAC7BtC,GAAW,KAEXG,QAAQC,IAAI,cACZJ,GAAW,IAxBP,SA2BF+B,EAAM,KA3BJ,OA6BRC,IA7BQ,4CAAH,qDAgCHD,EAAQ,WAAa,IAAZQ,EAAW,uDAAN,EAChB,OAAO,IAAI5B,SAAQ,SAAAC,GAAO,OAAI4B,WAAW5B,EAAS2B,OAgBtD,OAbAE,qBAAU,WAQN,OAPAxC,IAEAd,EAAMuD,GAAG,OAAO,WACZ9C,EAAaU,SAAU,KAIpB,eAGR,IAEM,sBACDqC,UAAS,cAAY5C,EAAU,UAAY,IAD1C,UAEL,uBACM6C,IAAQnD,EACdkD,UAAY,QACZE,UAAQ,IAER,sBACIF,UAAY,UADhB,UAEA,wBACOA,UAAY,MACnBG,QACI,WAAQvB,EAvII,cAoIhB,sBAFA,KAMuB,wBAChBoB,UAAY,MACnBG,QACI,WAAQvB,EAAMhC,IAHK,sBANvB,KAUuB,wBAChBoD,UAAY,MACnBG,QACI,WAAQd,KAHW,mBAVvB,SAPK,KAsBE,sBACHW,UAAY,YADT,UAEP,+EAFO,KAGyB,yKAHzB,KAIiF,sKAJjF,IAK6E,sIAL7E,KAMgE,+HANhE,QAtBF,QC7HEI,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,8BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCDdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1Bb,M","file":"static/js/main.a6ef66a6.chunk.js","sourcesContent":["export default __webpack_public_path__ + \"static/media/hey_sondn.8c2f8e9b.mp3\";","import React, { useEffect, useRef, useState } from 'react';\nimport * as mobilenet from '@tensorflow-models/mobilenet';\nimport * as knnClassifier from '@tensorflow-models/knn-classifier';\nimport { initNotifications, notify } from '@mycv/f8-notification';\nimport { Howl } from 'howler';\nimport * as tf from '@tensorflow/tfjs';\nimport soundURL from '../src/assest/hey_sondn.mp3';\nimport './App.css';\n\nvar sound = new Howl({\n    src: [soundURL]\n});\n\n\nconst NOT_TOUCH_LABLE = 'not_touch';\nconst TOUCHED_LABLE = 'touched';\nconst TRAINING_TIMES = 50;\n// Mức tin tưởng\nconst TOUCHED_CONFIDENCE = 0.8;\n\nfunction App() {\n    const video = useRef();\n    const classifier = useRef();\n    const canPlaySound = useRef(true);\n    const mobilenetModule = useRef();\n    const [touched, setTouched] = useState(false);\n\n    const init = async() => {\n        console.log('init...');\n        await setupCamera();\n        console.log('success');\n\n        classifier.current = knnClassifier.create();\n        mobilenetModule.current = await mobilenet.load();\n        console.log('setup success');\n        console.log('khong bo tay len mat va bam train1');\n\n        initNotifications({ cooldown: 3000 });\n    }\n\n    const setupCamera = () => {\n        return new Promise((resolve, reject) => {\n            navigator.getUserMedia = navigator.getUserMedia ||\n                navigator.webkitGetUserMedia ||\n                navigator.mozGetUserMedia ||\n                navigator.msGetUserMedia;\n            if (navigator.getUserMedia) {\n                navigator.getUserMedia({ video: true },\n                    stream => {\n                        video.current.srcObject = stream;\n                        video.current.addEventListener('loadeddata', resolve);\n                    },\n                    error => reject(error)\n                );\n            } else {\n                reject();\n            }\n        });\n    }\n    const train = async label => {\n            console.log(`${label} đang train cho máy`);\n            for (let i = 0; i < TRAINING_TIMES; ++i) {\n                console.log(`Progress ${parseInt((i+1) / TRAINING_TIMES * 100)}%`);\n\n                await training(label);\n            }\n        }\n        /**\n         * Bước 1 : train cho máy khuôn mặt không chạm tay\n         * Bước 2: train cho máy khôn măt chạm tay\n         * Bước 3: Lấy hinhd hiện tại, phân tích và so sánh\n         * ==> nếu mà matching với data khôn mặt chạm tay thì cảnh báo\n         * @param {*} label \n         * @returns \n         */\n\n    const training = label => {\n        return new Promise(async resolve => {\n            const embedding = mobilenetModule.current.infer(\n                video.current,\n                true\n            );\n            classifier.current.addExample(embedding, label);\n            await sleep(100);\n            resolve();\n        });\n    }\n\n    const run = async() => {\n        const embedding = mobilenetModule.current.infer(\n            video.current,\n            true\n        );\n        const result = await classifier.current.predictClass(embedding);\n\n        console.log('label:', result.label);\n        console.log('Confidences:', result.confidences);\n\n        if (\n            result.label === TOUCHED_LABLE &&\n            result.confidences[result.label] > TOUCHED_CONFIDENCE\n        ) {\n            if (canPlaySound.current) {\n                canPlaySound.current = false;\n                sound.play();\n            }\n            console.log('Touched');\n            sound.play();\n            notify('Bỏ tay ra!', { body: 'Your message.' });\n            setTouched(true);\n        } else {\n            console.log('No touched');\n            setTouched(false);\n        }\n\n        await sleep(200);\n\n        run();\n    }\n\n    const sleep = (ms = 0) => {\n        return new Promise(resolve => setTimeout(resolve, ms))\n    }\n\n    useEffect(() => {\n        init();\n\n        sound.on('end', function() {\n            canPlaySound.current = true;\n        });\n\n        //cleanup\n        return () => {\n\n        }\n    }, []);\n\n    return ( <\n        div className = { `App ${touched ? 'touched' : ''}` } >\n        <\n        video ref = { video }\n        className = \"video\"\n        autoPlay /\n        >\n        <\n        div className = \"control\" >\n        <\n        button className = \"btn\"\n        onClick = {\n            () => { train(NOT_TOUCH_LABLE) }\n        } > Train1 < /button>  <\n        button className = \"btn\"\n        onClick = {\n            () => { train(TOUCHED_LABLE) }\n        } > Train2 < /button>  <\n        button className = \"btn\"\n        onClick = {\n            () => { run() }\n        } > Run < /button>   <\n        /div>  <\n        div className = \"container\" >\n        <\n        h3 > Hướng dẫn sử dụng: < /h3>  <\n        p > Bước 1: nhấn train1 đề máy tính train khuôn mặt không chạm tay lên khuôn mặt < /p>  <\n        p > Bước 2: nhấn train2 đề máy tính train khuôn mặt có chạm tay lên khuôn mặt < /p> <\n        p > Bước 3: Lấy hình hiện tại trong video, phân tích và so sánh < /p>  <\n        p > nếu mà matching với data khôn mặt chạm tay thì cảnh báo < /p>  <\n        /div> <\n        /div>\n    );\n}\n\nexport default App;","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}